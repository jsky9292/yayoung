#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ì•¼ìš©ì‚¬ ì¹´í˜ í¬ë¡¤ëŸ¬ - ìˆ˜ë™ ë¡œê·¸ì¸ í›„ í¬ë¡¤ë§
"""

import time
import json
import os
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import pytz
import re

def search_yayongsa_gloves(user_dir='./'):
    """ì•¼ìš©ì‚¬ ì¹´í˜ì—ì„œ ê¸€ëŸ¬ë¸Œ ê²€ìƒ‰ - ìˆ˜ë™ ë¡œê·¸ì¸ í›„ í¬ë¡¤ë§"""

    print("\n" + "="*60)
    print("ì•¼ìš©ì‚¬ ì¹´í˜ í¬ë¡¤ëŸ¬ ì‹œì‘ (ë‹¤ìŒ ì¹´í˜)")
    print("="*60)

    # í¬ë¡¬ ë“œë¼ì´ë²„ ì„¤ì •
    options = webdriver.ChromeOptions()
    options.add_argument('--disable-blink-features=AutomationControlled')
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option('useAutomationExtension', False)
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")
    # ì°½ì´ ìë™ìœ¼ë¡œ ë‹«íˆì§€ ì•Šë„ë¡ ì„¤ì •
    options.add_experimental_option("detach", True)

    # ë¸Œë¼ìš°ì € ì°½ í‘œì‹œ (í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ OFF)
    print("ğŸ“Œ í¬ë¡¬ ë¸Œë¼ìš°ì €ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤...")
    print("   âš ï¸ ì°½ì´ ì—´ë¦¬ë©´ ì§ì ‘ ë¡œê·¸ì¸í•´ì£¼ì„¸ìš”!")

    driver = webdriver.Chrome(options=options)
    driver.maximize_window()

    # í˜ì´ì§€ ë¡œë“œ ì‹œê°„ ì œí•œ ì„¤ì •
    driver.set_page_load_timeout(60)
    driver.implicitly_wait(10)

    products = []

    try:
        # ì•¼ìš©ì‚¬ ì¹´í˜ë¡œ ë°”ë¡œ ì ‘ì†
        print("\n1. ì•¼ìš©ì‚¬ ì¹´í˜ í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤...")
        driver.get("https://cafe.daum.net/baseballsale")
        time.sleep(3)

        # ë¡œê·¸ì¸ í˜ì´ì§€ë¡œ ì´ë™í•  ìˆ˜ë„ ìˆìŒ
        current_url = driver.current_url

        # ë¡œê·¸ì¸ì´ í•„ìš”í•œ ê²½ìš° ìˆ˜ë™ ë¡œê·¸ì¸ ëŒ€ê¸°
        if 'login' in current_url.lower() or 'accounts.kakao.com' in current_url:
            print("\n" + "="*60)
            print("ğŸ” ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤!")
            print("="*60)
            print("ì§€ê¸ˆ ì—´ë¦° Chrome ë¸Œë¼ìš°ì €ì—ì„œ:")
            print("1. ì¹´ì¹´ì˜¤ ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸")
            print("2. 2ë‹¨ê³„ ì¸ì¦ ì™„ë£Œ")
            print("3. ì•¼ìš©ì‚¬ ì¹´í˜ ê°€ì… í™•ì¸")
            print("\nâ° ë¡œê·¸ì¸ ì™„ë£Œ í›„ Enter í‚¤ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”...")
            print("="*60)

            # ì‚¬ìš©ìê°€ ìˆ˜ë™ìœ¼ë¡œ ë¡œê·¸ì¸í•  ë•Œê¹Œì§€ ëŒ€ê¸°
            print("\nğŸ”„ ë¡œê·¸ì¸ì„ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘... (ìµœëŒ€ 30ì´ˆ)")

            # ë¡œê·¸ì¸ ì™„ë£Œ ëŒ€ê¸° (ìµœëŒ€ 30ì´ˆ)
            max_wait = 30
            wait_count = 0
            while wait_count < max_wait:
                time.sleep(5)
                wait_count += 5

                # í˜„ì¬ URL í™•ì¸
                current = driver.current_url
                if 'login' not in current.lower() and 'accounts.kakao.com' not in current:
                    print("\nâœ… ë¡œê·¸ì¸ ê°ì§€! í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
                    break

                print(f"â³ ëŒ€ê¸° ì¤‘... ({wait_count}/{max_wait}ì´ˆ)")

            if wait_count >= max_wait:
                print("\nâ° ì‹œê°„ ì´ˆê³¼. ë¡œê·¸ì¸ì„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                return []
        else:
            # ì´ë¯¸ ë¡œê·¸ì¸ë˜ì–´ ìˆëŠ” ê²½ìš°
            print("\nâœ… ì´ë¯¸ ë¡œê·¸ì¸ë˜ì–´ ìˆìŠµë‹ˆë‹¤!")
            print("\n5ì´ˆ í›„ í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            time.sleep(5)

        # ê²Œì‹œíŒìœ¼ë¡œ ì´ë™í•˜ì—¬ ë¡œê·¸ì¸ ìƒíƒœ ì¬í™•ì¸
        print("\n2. ë¡œê·¸ì¸ ìƒíƒœ í™•ì¸ ì¤‘...")
        driver.get("https://cafe.daum.net/baseballsale/79XF")
        time.sleep(3)

        current_url = driver.current_url
        page_source = driver.page_source

        # ì—¬ì „íˆ ë¡œê·¸ì¸ì´ ì•ˆë˜ì–´ ìˆë‹¤ë©´
        if 'login' in current_url.lower() or 'accounts.kakao.com' in current_url or 'ë¡œê·¸ì¸' in page_source:
            print("\nâŒ ë¡œê·¸ì¸ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            print("ë¸Œë¼ìš°ì €ë¥¼ ë‹«ê³  ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return []
        else:
            print("âœ… ë¡œê·¸ì¸ í™•ì¸! í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

        # í¬ë¡¤ë§í•  ê²Œì‹œíŒ ëª©ë¡
        boards = [
            {"name": "ì¤‘ê³ ê¸€ëŸ¬ë¸Œë²¼ë£©ì‹œì¥", "id": "79XF", "board": "ì¤‘ê³ ê¸€ëŸ¬ë¸Œë²¼ë£©ì‹œì¥"},
            {"name": "ìƒˆì œí’ˆ ê¸€ëŸ¬ë¸Œ ë²¼ë£©ì‹œì¥", "id": "2Fsn", "board": "ìƒˆì œí’ˆ ê¸€ëŸ¬ë¸Œ ë²¼ë£©ì‹œì¥"}
        ]

        # ê° ê²Œì‹œíŒ í¬ë¡¤ë§
        for board_info in boards:
            print(f"\n3. {board_info['name']} ê²Œì‹œíŒìœ¼ë¡œ ì´ë™...")
            print(f"ğŸ“… ìµœì‹  ê²Œì‹œê¸€ í¬ë¡¤ë§...")

            # ê²Œì‹œíŒ í˜ì´ì§€ë¥¼ ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬
            driver.get(f"https://cafe.daum.net/baseballsale/{board_info['id']}?sort=R")  # R=ìµœì‹ ìˆœ
            time.sleep(3)

            # í˜ì´ì§€ê°€ ì™„ì „íˆ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°
            time.sleep(3)

            # iframeìœ¼ë¡œ ì „í™˜ (ë‹¤ìŒ ì¹´í˜ëŠ” iframe ì‚¬ìš©) - IDê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
            iframe_found = False

            # iframe ID ë‹¤ì–‘í•œ ì‹œë„
            iframe_ids = ["cafe_main", "down", "cafe_content"]

            for iframe_id in iframe_ids:
                try:
                    iframe = driver.find_element(By.ID, iframe_id)
                    driver.switch_to.frame(iframe)
                    print(f"   âœ… iframe ì „í™˜ ì„±ê³µ: {iframe_id}")
                    iframe_found = True
                    time.sleep(1)
                    break
                except:
                    continue

            if not iframe_found:
                # nameìœ¼ë¡œ ì‹œë„
                try:
                    iframe = driver.find_element(By.NAME, "cafe_main")
                    driver.switch_to.frame(iframe)
                    print("   âœ… iframe ì „í™˜ ì„±ê³µ (name)")
                    iframe_found = True
                    time.sleep(1)
                except:
                    print("   â„¹ï¸ iframe ì—†ìŒ - ì§ì ‘ íŒŒì‹±")

            # ê²Œì‹œê¸€ ëª©ë¡ íŒŒì‹±
            print(f"\n4. {board_info['name']} ê²Œì‹œê¸€ ëª©ë¡ íŒŒì‹±...")

            # ê²€ìƒ‰ì–´ë¡œ í•„í„°ë§
            print("   'ê¸€ëŸ¬ë¸Œ' ê´€ë ¨ ê²Œì‹œê¸€ë§Œ ìˆ˜ì§‘í•©ë‹ˆë‹¤...")

            # í˜ì´ì§€ë„¤ì´ì…˜ - 3í˜ì´ì§€ê¹Œì§€
            max_pages = 3
            for page_num in range(1, max_pages + 1):
                print(f"\n   ğŸ“„ {page_num}í˜ì´ì§€ ìˆ˜ì§‘ ì¤‘...")

                # í˜ì´ì§€ ì´ë™ (2í˜ì´ì§€ë¶€í„°)
                if page_num > 1:
                    try:
                        # í˜ì´ì§€ ë²ˆí˜¸ í´ë¦­
                        # ì…€ë ‰í„° íŒ¨í„´: li:nth-child(í˜ì´ì§€ë²ˆí˜¸) > a > span
                        page_selector = f"#primaryContent > div.cont_boardlist > div.paging_g > div.inner_paging_number > ol > li:nth-child({page_num}) > a"
                        page_link = driver.find_element(By.CSS_SELECTOR, page_selector)
                        page_link.click()
                        time.sleep(2)  # í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸°
                        print(f"   âœ… {page_num}í˜ì´ì§€ë¡œ ì´ë™")
                    except Exception as e:
                        print(f"   âš ï¸ {page_num}í˜ì´ì§€ ì´ë™ ì‹¤íŒ¨: {e}")
                        break  # í˜ì´ì§€ê°€ ì—†ìœ¼ë©´ ì¤‘ë‹¨

                # ë‹¤ìŒ ì¹´í˜ ê²Œì‹œê¸€ ëª©ë¡ ì°¾ê¸°
                articles = []

                # ë‹¤ìŒ ì¹´í˜ëŠ” ê²Œì‹œê¸€ì´ trë¡œ êµ¬ì„±ë¨
                # ì‹¤ì œ ê²Œì‹œê¸€ ì…€ë ‰í„° ì‚¬ìš©
                # ë‹¤ìŒ ì¹´í˜ëŠ” ë³´í†µ tbody > tr êµ¬ì¡°ë¡œ ë˜ì–´ ìˆìŒ
                # ì‹¤ì œ í…Œì´ë¸” í´ë˜ìŠ¤: tbl_board_g board_check
                articles = driver.find_elements(By.CSS_SELECTOR, "table.tbl_board_g tbody tr")

                if not articles:
                    # ëŒ€ì²´ ì…€ë ‰í„° 1: í´ë˜ìŠ¤ëª… ì—†ëŠ” í…Œì´ë¸”
                    articles = driver.find_elements(By.CSS_SELECTOR, "table tbody tr")

                if not articles:
                    # ëŒ€ì²´ ì…€ë ‰í„° 2: bbsList (ì´ì „ ë²„ì „)
                    articles = driver.find_elements(By.CSS_SELECTOR, "table.bbsList tbody tr")

                if not articles:
                    # ëŒ€ì²´ ì…€ë ‰í„° 3: ëª¨ë“  tr ì°¾ê³  í•„í„°ë§
                    articles = driver.find_elements(By.TAG_NAME, "tr")
                    # í—¤ë”ì™€ ê³µì§€ ì œì™¸ - í•˜ì§€ë§Œ ì „ì²´ ìˆ˜ì§‘
                    articles = [a for a in articles if a.text]

                # ë””ë²„ê¹…: HTML êµ¬ì¡° í™•ì¸
                if not articles:
                    print("\n   âš ï¸ ê²Œì‹œê¸€ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. HTML êµ¬ì¡° í™•ì¸ ì¤‘...")

                # í˜ì´ì§€ ì†ŒìŠ¤ ì¼ë¶€ ì¶œë ¥
                page_source = driver.page_source[:2000]
                if 'bbsList' in page_source:
                    print("   - bbsList í´ë˜ìŠ¤ ë°œê²¬")
                if 'listBody' in page_source:
                    print("   - listBody ID ë°œê²¬")

                # ëª¨ë“  í…Œì´ë¸” ì°¾ê¸°
                tables = driver.find_elements(By.TAG_NAME, "table")
                print(f"   - ì „ì²´ table ìˆ˜: {len(tables)}")

                # ëª¨ë“  tr ìš”ì†Œ ì°¾ê¸°
                all_trs = driver.find_elements(By.TAG_NAME, "tr")
                print(f"   - ì „ì²´ tr ìˆ˜: {len(all_trs)}")

                # ê²Œì‹œê¸€ ë§í¬ ì§ì ‘ ì°¾ê¸°
                post_links = driver.find_elements(By.CSS_SELECTOR, "a[href*='/baseballsale/']")
                print(f"   - ê²Œì‹œê¸€ ë§í¬ ìˆ˜: {len(post_links)}")

                if post_links:
                    for i, link in enumerate(post_links[:3]):
                        print(f"   - ë§í¬ {i+1}: {link.text[:50] if link.text else 'No text'}")

                # ë§í¬ ëª¨ë“œ í™•ì¸ìš© ë³€ìˆ˜
                use_link_mode = False

                print(f"ë°œê²¬ëœ ê²Œì‹œê¸€: {len(articles)}ê°œ")

                # í˜„ì¬ í˜ì´ì§€ì˜ ê²Œì‹œê¸€ ì²˜ë¦¬
                for idx, article in enumerate(articles[:50], 1):  # ìµœëŒ€ 50ê°œê¹Œì§€ë§Œ
                    try:
                        product_data = {}
                        product_data['board'] = board_info['board']  # ê²Œì‹œíŒ ì •ë³´ ì¶”ê°€

                        # ê³µì§€ì‚¬í•­ ì œì™¸ - ì²« ë²ˆì§¸ TDì— ê³µì§€/í•„ë…ì´ ìˆìœ¼ë©´ ìŠ¤í‚µ
                        first_td = article.find_element(By.TAG_NAME, "td")
                        if first_td and ("ê³µì§€" in first_td.text or "í•„ë…" in first_td.text):
                            continue

                        # ì œëª© ì°¾ê¸° - ë‹¤ìŒ ì¹´í˜ êµ¬ì¡°ì— ë§ê²Œ
                        title_found = False

                        # TDë“¤ì„ ë¨¼ì € ì°¾ê¸°
                        tds = article.find_elements(By.TAG_NAME, "td")

                        # ë‘ ë²ˆì§¸ TDì— ìˆëŠ” a íƒœê·¸ê°€ ì œëª© ë§í¬ (ì²« ë²ˆì§¸ëŠ” í•„ë…/ê³µì§€ í‘œì‹œ)
                        if len(tds) >= 2:
                            try:
                                title_elem = tds[1].find_element(By.TAG_NAME, "a")
                                product_data['title'] = title_elem.text.strip()
                                product_data['url'] = title_elem.get_attribute('href')
                                title_found = True
                            except:
                                pass

                        # ëŒ€ì²´ ë°©ë²•: a íƒœê·¸ ì§ì ‘ ì°¾ê¸°
                        if not title_found:
                            try:
                                title_elem = article.find_element(By.CSS_SELECTOR, "a[href*='bbs_read']")
                                product_data['title'] = title_elem.text.strip()
                                product_data['url'] = title_elem.get_attribute('href')
                                title_found = True
                            except:
                                product_data['title'] = ''
                                product_data['url'] = ''

                        # ì œëª©ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ
                        if not product_data['title']:
                            continue

                    # ê²½ì‹ ê¸€ëŸ¬ë¸Œë§Œ í•„í„°ë§ (ì¼ë‹¨ ëª¨ë“  ê¸€ëŸ¬ë¸Œ ìˆ˜ì§‘)
                    # if 'ì—°ì‹' in product_data['title'] or 'ì†Œí”„íŠ¸' in product_data['title']:
                    #     continue
                    # if 'ê¸€ëŸ¬ë¸Œ' not in product_data['title'] and 'ê¸€ëŸ½' not in product_data['title']:
                    #     continue

                    # íŒë§¤ì™„ë£Œ ìƒí’ˆ ì œì™¸
                    sold_keywords = ['íŒë§¤ì™„ë£Œ', 'ì™„ë£Œ', 'ì¢…ë£Œ', 'sold', 'SOLD', 'ê±°ë˜ì™„ë£Œ', 'íŒì™„', 'íŒ”ë¦¼', 'ì˜ˆì•½ì™„ë£Œ']
                    if any(keyword in product_data['title'] for keyword in sold_keywords):
                        print(f"  â­ï¸ íŒë§¤ì™„ë£Œ ìƒí’ˆ ìŠ¤í‚µ: {product_data['title'][:30]}...")
                        continue

                    # ì‘ì„±ì ì°¾ê¸°
                    try:
                        author = article.find_element(By.CSS_SELECTOR, "td.writer").text.strip()
                        product_data['author'] = author
                    except:
                        try:
                            author = article.find_element(By.CSS_SELECTOR, "td.td_writer").text.strip()
                            product_data['author'] = author
                        except:
                            try:
                                # tdì˜ ìˆœì„œë¡œ ì°¾ê¸° (ë³´í†µ 3ë²ˆì§¸ td)
                                tds = article.find_elements(By.TAG_NAME, "td")
                                if len(tds) >= 3:
                                    product_data['author'] = tds[2].text.strip()
                                else:
                                    product_data['author'] = ''
                            except:
                                product_data['author'] = ''

                    # ì‘ì„±ì¼ ì°¾ê¸°
                    try:
                        date = article.find_element(By.CSS_SELECTOR, "td.date").text.strip()
                        product_data['date'] = date
                    except:
                        try:
                            date = article.find_element(By.CSS_SELECTOR, "td.td_date").text.strip()
                            product_data['date'] = date
                        except:
                            try:
                                # tdì˜ ìˆœì„œë¡œ ì°¾ê¸° (ë³´í†µ 4ë²ˆì§¸ td)
                                tds = article.find_elements(By.TAG_NAME, "td")
                                if len(tds) >= 4:
                                    product_data['date'] = tds[3].text.strip()
                                else:
                                    product_data['date'] = ''
                            except:
                                product_data['date'] = ''

                    # ì¡°íšŒìˆ˜ ì°¾ê¸°
                    try:
                        views = article.find_element(By.CSS_SELECTOR, "td.view").text.strip()
                        product_data['views'] = views
                    except:
                        try:
                            views = article.find_element(By.CSS_SELECTOR, "td.td_view").text.strip()
                            product_data['views'] = views
                        except:
                            try:
                                # tdì˜ ìˆœì„œë¡œ ì°¾ê¸° (ë³´í†µ 5ë²ˆì§¸ td)
                                tds = article.find_elements(By.TAG_NAME, "td")
                                if len(tds) >= 5:
                                    product_data['views'] = tds[4].text.strip()
                                else:
                                    product_data['views'] = '0'
                            except:
                                product_data['views'] = '0'

                    # ìƒì„¸ í˜ì´ì§€ì—ì„œ ê°€ê²©ê³¼ ì´ë¯¸ì§€ ì¶”ì¶œ
                    price, images = extract_details_from_article(driver, product_data['url'])
                    product_data['price'] = price
                    product_data['images'] = images

                    # ì§€ì—­ ì¶”ì¶œ
                    location = 'ë¯¸ìƒ'
                    location_keywords = ['ì„œìš¸', 'ê²½ê¸°', 'ì¸ì²œ', 'ë¶€ì‚°', 'ëŒ€êµ¬', 'ê´‘ì£¼', 'ëŒ€ì „', 'ìš¸ì‚°', 'ì„¸ì¢…',
                                       'ê°•ì›', 'ì¶©ë¶', 'ì¶©ë‚¨', 'ì „ë¶', 'ì „ë‚¨', 'ê²½ë¶', 'ê²½ë‚¨', 'ì œì£¼']
                    for loc in location_keywords:
                        if loc in product_data['title']:
                            location = loc
                            break
                    product_data['location'] = location

                    # ë¸Œëœë“œ ì¶”ì¶œ
                    brand = extract_brand_from_title(product_data['title'])
                    product_data['brand'] = brand

                    # í¬ì§€ì…˜ ì¶”ì¶œ
                    position = extract_position_from_title(product_data['title'])
                    product_data['position'] = position

                    # ìƒíƒœ ì¶”ì¶œ
                    condition = 'ì¤‘ê³ '
                    if 'ìƒˆìƒí’ˆ' in title_lower or 'ì‹ í’ˆ' in title_lower or 'ë¯¸ì‚¬ìš©' in title_lower:
                        condition = 'ì‹ í’ˆ'
                    product_data['condition'] = condition

                    products.append(product_data)

                    print(f"  [{idx}] {product_data['title'][:40]}...")
                    if price_krw > 0:
                        print(f"      ğŸ’° ê°€ê²©: â‚©{price_krw:,}")
                    print(f"      ğŸ“ ì§€ì—­: {location} | ğŸ·ï¸ {brand} | ğŸ“… {date}")

                except Exception as e:
                    print(f"  âŒ ê²Œì‹œê¸€ {idx} íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue

            # iframeì—ì„œ ë²—ì–´ë‚˜ê¸°
            try:
                driver.switch_to.default_content()
            except:
                pass

    except Exception as e:
        print(f"\nâŒ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")

    finally:
        # ë¸Œë¼ìš°ì € ë‹«ê¸° (ì‚¬ìš©ìê°€ ì§ì ‘ ë‹«ì„ ë•Œê¹Œì§€ ìœ ì§€)
        # driver.quit()
        print("\ní¬ë¡¤ë§ ì™„ë£Œ. ë¸Œë¼ìš°ì €ëŠ” ì—´ë ¤ ìˆìŠµë‹ˆë‹¤.")

    # ê²°ê³¼ ì €ì¥
    if products:
        # í•œêµ­ ì‹œê°„ìœ¼ë¡œ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
        kst = pytz.timezone('Asia/Seoul')
        now = datetime.now(kst)
        timestamp = now.strftime('%Y%m%d_%H%M%S')

        print(f"\nğŸ“… í˜„ì¬ ì‹œê°„: {now.strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„ %Sì´ˆ')}")

        # ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
        data_dir = 'data'
        os.makedirs(data_dir, exist_ok=True)

        # JSON íŒŒì¼ë¡œ ì €ì¥ (ë©”íƒ€ë°ì´í„° ì¶”ê°€)
        filename = f'yayongsa_{timestamp}.json'
        filepath = os.path.join(data_dir, filename)

        data = {
            'crawled_at': now.isoformat(),
            'crawled_date': now.strftime('%Y-%m-%d'),
            'crawled_time': now.strftime('%H:%M:%S'),
            'total_count': len(products),
            'products': products
        }

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"\nâœ… ë°ì´í„° ì €ì¥ ì™„ë£Œ: {filepath}")
        print(f"   ì´ {len(products)}ê°œ ìƒí’ˆ")
        print(f"   í¬ë¡¤ë§ ì‹œê°„: {now.strftime('%Y-%m-%d %H:%M:%S')}")

    return products

def extract_details_from_article(driver, article_url):
    """ìƒì„¸ í˜ì´ì§€ì—ì„œ ê°€ê²©ê³¼ ì´ë¯¸ì§€ ì¶”ì¶œ"""
    price = 0
    images = []

    try:
        # í˜„ì¬ ì°½ í•¸ë“¤ ì €ì¥
        main_window = driver.current_window_handle

        # ìƒˆ íƒ­ì—ì„œ ìƒì„¸ í˜ì´ì§€ ì—´ê¸°
        driver.execute_script(f"window.open('{article_url}', '_blank');")

        # ìƒˆ íƒ­ìœ¼ë¡œ ì „í™˜
        driver.switch_to.window(driver.window_handles[-1])
        time.sleep(2)

        # iframe ì „í™˜ ì‹œë„
        try:
            iframe = driver.find_element(By.ID, "down")
            driver.switch_to.frame(iframe)
        except:
            pass

        # ê°€ê²© ì¶”ì¶œ - ë³¸ë¬¸ì—ì„œ ìˆ«ì ì°¾ê¸°
        try:
            content_element = driver.find_element(By.ID, "user_contents")
            content_text = content_element.text

            # ê°€ê²© íŒ¨í„´ ì°¾ê¸° (ë§Œì›, ì› ë“±)
            price_patterns = [
                r'(\d{1,3}(?:,\d{3})*)\s*ë§Œì›',
                r'(\d{1,3}(?:,\d{3})*)\s*ì›',
                r'ê°€ê²©[:\s]*(\d{1,3}(?:,\d{3})*)',
                r'íŒë§¤ê°€[:\s]*(\d{1,3}(?:,\d{3})*)',
            ]

            for pattern in price_patterns:
                matches = re.findall(pattern, content_text)
                if matches:
                    price_str = matches[0].replace(',', '')
                    price = int(price_str)
                    # ë§Œì› ë‹¨ìœ„ë©´ 10000 ê³±í•˜ê¸°
                    if 'ë§Œì›' in content_text:
                        price *= 10000
                    break

        except Exception as e:
            print(f"    ê°€ê²© ì¶”ì¶œ ì‹¤íŒ¨: {e}")

        # ì´ë¯¸ì§€ ì¶”ì¶œ
        try:
            # ì—¬ëŸ¬ ì´ë¯¸ì§€ ì…€ë ‰í„° ì‹œë„
            image_selectors = [
                "#user_contents > div > img",
                "#user_contents img",
                ".user_contents img",
                "img[src*='cafefile']"
            ]

            for selector in image_selectors:
                img_elements = driver.find_elements(By.CSS_SELECTOR, selector)
                if img_elements:
                    for img in img_elements[:5]:  # ìµœëŒ€ 5ê°œê¹Œì§€
                        img_src = img.get_attribute('src')
                        if img_src and 'cafefile' in img_src:
                            images.append(img_src)
                    break

        except Exception as e:
            print(f"    ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

        # íƒ­ ë‹«ê³  ì›ë˜ íƒ­ìœ¼ë¡œ ëŒì•„ê°€ê¸°
        driver.close()
        driver.switch_to.window(main_window)

    except Exception as e:
        print(f"    ìƒì„¸ í˜ì´ì§€ ì ‘ê·¼ ì‹¤íŒ¨: {e}")
        # ì‹¤íŒ¨ ì‹œ ì›ë˜ íƒ­ìœ¼ë¡œ ëŒì•„ê°€ê¸°
        try:
            driver.switch_to.window(main_window)
        except:
            pass

    return price, images

def collect_articles(driver, articles, board_name):
    """ê²Œì‹œê¸€ ìˆ˜ì§‘ í•¨ìˆ˜ - step9 ë¡œì§ ì‚¬ìš©"""
    products = []

    for idx, article in enumerate(articles[:10], 1):  # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 10ê°œë§Œ
        try:
            product_data = {}
            product_data['board'] = board_name

            # TDë“¤ ì°¾ê¸°
            tds = article.find_elements(By.TAG_NAME, "td")

            # ë‘ ë²ˆì§¸ TDì˜ a íƒœê·¸ì—ì„œ ì œëª© ì¶”ì¶œ
            if len(tds) >= 2:
                try:
                    link = tds[1].find_element(By.TAG_NAME, "a")
                    product_data['title'] = link.text.strip()
                    product_data['url'] = link.get_attribute('href')
                except:
                    # ëŒ€ì²´ ë°©ë²•
                    try:
                        link = article.find_element(By.CSS_SELECTOR, "a[href*='bbs_read']")
                        product_data['title'] = link.text.strip()
                        product_data['url'] = link.get_attribute('href')
                    except:
                        continue
            else:
                continue

            # ì œëª©ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ
            if not product_data['title']:
                continue

            # ê³µì§€ì‚¬í•­ ì œì™¸
            if 'ê³µì§€' in product_data['title'] or 'í•„ë…' in product_data['title']:
                continue

            # ë‚˜ë¨¸ì§€ ë°ì´í„° ì¶”ì¶œ
            if len(tds) >= 5:
                product_data['author'] = tds[2].text.strip() if len(tds) > 2 else ''
                product_data['date'] = tds[3].text.strip() if len(tds) > 3 else ''
                product_data['views'] = tds[4].text.strip() if len(tds) > 4 else '0'
            else:
                product_data['author'] = ''
                product_data['date'] = ''
                product_data['views'] = '0'

            # ìƒì„¸ í˜ì´ì§€ì—ì„œ ê°€ê²©ê³¼ ì´ë¯¸ì§€ ì¶”ì¶œ
            price, images = extract_details_from_article(driver, product_data['url'])
            product_data['price'] = price
            product_data['images'] = images

            # ë¸Œëœë“œ ì¶”ì¶œ
            product_data['brand'] = extract_brand_from_title(product_data['title'])

            # í¬ì§€ì…˜ ì¶”ì¶œ
            product_data['position'] = extract_position_from_title(product_data['title'])

            # ì§€ì—­ ì„¤ì •
            product_data['location'] = 'ë¯¸ìƒ'

            # ìƒíƒœ ì„¤ì •
            title_lower = product_data['title'].lower()
            if 'ìƒˆìƒí’ˆ' in title_lower or 'ì‹ í’ˆ' in title_lower:
                product_data['condition'] = 'ì‹ í’ˆ'
            else:
                product_data['condition'] = 'ì¤‘ê³ '

            products.append(product_data)
            print(f"  âœ… [{idx}] {product_data['title'][:40]}...")

        except Exception as e:
            print(f"  âŒ [{idx}] íŒŒì‹± ì˜¤ë¥˜: {e}")
            continue

    return products

def extract_brand_from_title(title):
    """ì œëª©ì—ì„œ ë¸Œëœë“œ ì¶”ì¶œ"""
    brands = {
        'ë¯¸ì¦ˆë…¸': 'Mizuno',
        'mizuno': 'Mizuno',
        'MIZUNO': 'Mizuno',
        'ìœŒìŠ¨': 'Wilson',
        'wilson': 'Wilson',
        'WILSON': 'Wilson',
        'ë¡¤ë§ìŠ¤': 'Rawlings',
        'rawlings': 'Rawlings',
        'RAWLINGS': 'Rawlings',
        'ì œíŠ¸': 'ZETT',
        'zett': 'ZETT',
        'ZETT': 'ZETT',
        'SSK': 'SSK',
        'ssk': 'SSK',
        'ì•„í†°ì¦ˆ': 'ATOMS',
        'atoms': 'ATOMS',
        'ATOMS': 'ATOMS',
        'ì•„ì‹ìŠ¤': 'ASICS',
        'asics': 'ASICS',
        'ASICS': 'ASICS',
        'ë‚˜ì´í‚¤': 'Nike',
        'nike': 'Nike',
        'NIKE': 'Nike',
        'ì•„ë””ë‹¤ìŠ¤': 'Adidas',
        'adidas': 'Adidas',
        'ì–¸ë”ì•„ë¨¸': 'Under Armour',
        'under armour': 'Under Armour',
        'underarmour': 'Under Armour',
        '44': '44ê¸€ëŸ¬ë¸Œ',
        'IP': 'IP Select',
        'ì•„ì´í”¼': 'IP Select',
    }

    title_lower = title.lower()
    for keyword, brand_name in brands.items():
        if keyword.lower() in title_lower:
            return brand_name

    return 'ê¸°íƒ€'

def extract_position_from_title(title):
    """ì œëª©ì—ì„œ í¬ì§€ì…˜ ì¶”ì¶œ"""
    positions = {
        'ë‚´ì•¼': 'ë‚´ì•¼ìˆ˜',
        'ì™¸ì•¼': 'ì™¸ì•¼ìˆ˜',
        'íˆ¬ìˆ˜': 'íˆ¬ìˆ˜',
        'í¬ìˆ˜': 'í¬ìˆ˜',
        'ì˜¬ë¼ìš´ë“œ': 'ì˜¬ë¼ìš´ë“œ',
        'ìœ ê²©ìˆ˜': 'ë‚´ì•¼ìˆ˜',
        '2ë£¨ìˆ˜': 'ë‚´ì•¼ìˆ˜',
        '3ë£¨ìˆ˜': 'ë‚´ì•¼ìˆ˜',
        '1ë£¨ìˆ˜': 'ë‚´ì•¼ìˆ˜',
    }

    for keyword, position_name in positions.items():
        if keyword in title:
            return position_name

    return 'ì˜¬ë¼ìš´ë“œ'

if __name__ == "__main__":
    # ì‚¬ìš©ì ë””ë ‰í† ë¦¬ ì„¤ì •
    import sys
    user_dir = sys.argv[1] if len(sys.argv) > 1 else './'

    products = search_yayongsa_gloves(user_dir)
    print(f"\nì´ {len(products)}ê°œì˜ ì•¼ìš©ì‚¬ ìƒí’ˆì„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")